{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Baseline Transfer Learning.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"EvOLHpULfCkx","colab_type":"text"},"source":["# Baseline Transfer Learning Model for TrashNet Classification"]},{"cell_type":"markdown","metadata":{"id":"p1YGdWgaxh0V","colab_type":"text"},"source":["Our baseline model will include a pretrained DenseNet feature extractor with a shallow and wide CNN head. This model will have a homogenous learning rate. We are going to use K-Fold CV as well as F1 score and multi-class AUC to validate our model.\n","\n","This model acts as a stepping stone / template for future experiments."]},{"cell_type":"code","metadata":{"id":"a3yToMaN05im","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593413909853,"user_tz":-480,"elapsed":4376,"user":{"displayName":"Alan Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAIjD1oE9ht91bAhm8R8PCRYmXLAkyZi1AcXyp=s64","userId":"03211566715491417040"}},"outputId":"569c6352-bb0e-4deb-eed3-46af4ade18c3"},"source":["!pip install pkbar"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pkbar in /usr/local/lib/python3.6/dist-packages (0.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pkbar) (1.18.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8RsfLTKGf7mD","colab_type":"code","colab":{}},"source":["import os\n","import pkbar\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import pandas as pd\n","import numpy as np\n","from PIL import Image\n","from skimage import io, transform\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","from torchvision import models\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n","from sklearn.metrics import roc_auc_score, f1_score, accuracy_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RokNiLIBvotp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593413910232,"user_tz":-480,"elapsed":4731,"user":{"displayName":"Alan Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAIjD1oE9ht91bAhm8R8PCRYmXLAkyZi1AcXyp=s64","userId":"03211566715491417040"}},"outputId":"b3f72533-32df-4549-cef2-6073b5855fab"},"source":["drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fnWEP0kovqfI","colab_type":"code","colab":{}},"source":["os.listdir('drive/My Drive/Colab Notebooks/Trash Classification')\n","root = 'drive/My Drive/Colab Notebooks/Trash Classification'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9_bhYNXDb_KV","colab_type":"text"},"source":["## Data Pre-processing\n","For the baseline model, we will not be applying any data augmentation or color manipulation.\n","- Get the index CSV file that includes all files their respective directory and labels."]},{"cell_type":"code","metadata":{"id":"GoEjfYONFGIz","colab_type":"code","colab":{}},"source":["dataset = 'trashnet'\n","csv_path = os.path.join(os.path.join(root, dataset), f'{dataset}_index.csv')\n","trash_index = pd.read_csv(csv_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AK2sRJtkh5Nn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1593413910233,"user_tz":-480,"elapsed":4705,"user":{"displayName":"Alan Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAIjD1oE9ht91bAhm8R8PCRYmXLAkyZi1AcXyp=s64","userId":"03211566715491417040"}},"outputId":"2696904a-7abc-42d9-c9e3-53159623c3ea"},"source":["print(trash_index)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["                    Filename  metal  cardboard  paper  trash  glass  plastic\n","0         metal/metal282.jpg      1          0      0      0      0        0\n","1         metal/metal296.jpg      1          0      0      0      0        0\n","2           metal/metal2.jpg      1          0      0      0      0        0\n","3         metal/metal255.jpg      1          0      0      0      0        0\n","4         metal/metal241.jpg      1          0      0      0      0        0\n","...                      ...    ...        ...    ...    ...    ...      ...\n","2525  plastic/plastic441.jpg      0          0      0      0      0        1\n","2526  plastic/plastic482.jpg      0          0      0      0      0        1\n","2527  plastic/plastic327.jpg      0          0      0      0      0        1\n","2528  plastic/plastic323.jpg      0          0      0      0      0        1\n","2529  plastic/plastic109.jpg      0          0      0      0      0        1\n","\n","[2530 rows x 7 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aPhbaYIAqQDq","colab_type":"text"},"source":["### Trash Dataset\n","Dataset object to handle various sets of data that we will be dealing with including: TrashNet, ISBNet, and ISBNet extended.\n","\n"]},{"cell_type":"code","metadata":{"id":"hY5KgUVwxXFz","colab_type":"code","colab":{}},"source":["class TrashDataset(Dataset):\n","  def __init__(self, csv_file, directory, root_dir, transform=None):\n","    \"\"\"\n","    csv_file: CSV file that contains information about each image and their labels.\n","    directory: the directory where the trash data is kept\n","    root_dir: path to the `directory`\n","    transform: optional augmentations that are to be applied onto the images\n","    \"\"\"\n","    self.images = os.path.join(root_dir, directory)\n","    self.csv = csv_file\n","    self.transform = transform\n","  \n","  def __len__(self):\n","    return len(self.csv)\n","  \n","  def __getitem__(self, idx):\n","    if torch.is_tensor(idx):\n","      idx = idx.tolist()\n","    \n","    img_name = os.path.join(self.images, self.csv.iloc[idx, 0])\n","    image = Image.open(img_name)\n","    labels = self.csv.iloc[idx, 1:]\n","    sample = {'image': image,\n","              'label': torch.tensor(labels.tolist(), dtype=torch.float)}\n","\n","    if self.transform:\n","      sample['image'] = self.transform(sample['image'])\n","\n","    return sample"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dr8dFmpmteKB","colab_type":"text"},"source":["## Model and Training Setup\n","- VGG16 pretrained with ImageNet\n","- Wide and shallow CNN with fully connected and log-softmax activation\n","- CrossEntropy loss and Adam optimizer."]},{"cell_type":"markdown","metadata":{"id":"2sR1CiTexs0z","colab_type":"text"},"source":["### Device Setup"]},{"cell_type":"code","metadata":{"id":"eSjjNBUlxxiv","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aVySPVh1uVy9","colab_type":"text"},"source":["### Constants"]},{"cell_type":"code","metadata":{"id":"t5ovoB5fuaox","colab_type":"code","colab":{}},"source":["FOLDS = 5\n","EPOCHS = 150\n","BATCH_SIZE = 16"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FqhMCfX0s5wr","colab_type":"text"},"source":["### Model"]},{"cell_type":"code","metadata":{"id":"1IHUz16JsA2i","colab_type":"code","colab":{}},"source":["class Net(nn.Module):\n","  def __init__(self):\n","    super(Net, self).__init__()\n","    self.model = models.vgg16_bn(pretrained=True)\n","    # Remove classification layers so that we are able to add our own CNN layers\n","    c = 0\n","    vgg = next(self.model.children()) \n","    for param in vgg:\n","      if c <= 37:\n","        if hasattr(param, 'weight') and hasattr(param, 'bias'):\n","          param.weight.requires_grad = False\n","          param.bias.requires_grad = False\n","        param.requires_grad = False\n","      c += 1\n","    # self.model.classifier[6] = nn.Sequential(\n","    #     nn.Linear(4096, 1024, bias=True),\n","    #     nn.BatchNorm1d(1024),\n","    #     nn.Dropout(0.25),\n","    #     nn.Linear(1024, 512, bias=True),\n","    #     nn.BatchNorm1d(512),\n","    #     nn.Dropout(0.5),\n","    #     nn.ReLU(),\n","    #     nn.Linear(512,6,bias=True)\n","    # )\n","    self.model = nn.Sequential(*list(self.model.children())[:2])\n","    self.dropout2d = nn.Dropout2d(p=0.25)\n","    self.dropout1d = nn.Dropout(p=0.50)\n","    self.relu = nn.ReLU()\n","    self.conv1 = nn.Conv2d(512, 100, 2)\n","    self.conv2 = nn.Conv2d(100, 100, 2)\n","    self.conv3 = nn.Conv2d(100, 100, 3)\n","    self.bacthnorm1 = nn.BatchNorm2d(100)\n","    self.batchnorm2 = nn.BatchNorm2d(100 )\n","    self.pooling = nn.MaxPool2d(3)\n","    self.fc1 = nn.Linear(100, 6, bias=True)\n","    self.softmax = nn.LogSoftmax(dim=0)\n","  def forward(self, x):\n","    features = self.model(x)\n","    # convolution blocks\n","    out = self.dropout2d(features)\n","    out = F.relu(self.conv1(features))\n","    out = self.bacthnorm1(out)\n","    out = F.relu(self.conv2(out))\n","    out = self.batchnorm2(out)\n","    # pooling, dropout and fully connected\n","    out = self.pooling(out)\n","    out = self.dropout1d(out)\n","    flattened = out.view(-1, self.num_flat_features(out))\n","    out = self.fc1(flattened)\n","    return out\n","  \n","  def num_flat_features(self, x):\n","    \"\"\"\n","    https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py\n","    \"\"\"\n","    size = x.size()[1:]  # get all dimensions except for batch size\n","    features = 1\n","    for s in size:\n","      features *= s\n","    return features\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FRRDY5q7uzRy","colab_type":"text"},"source":["### KFold Training and CV\n","* KFold setup with `StratifiedKFold`\n","* Creating Dataloaders in training loop.\n","* Using Adam and CrossEntropy Loss\n","* Center crop on images to make them 224x224 so VGG will be able to take them."]},{"cell_type":"code","metadata":{"id":"BM_t7ZnBuUaK","colab_type":"code","colab":{}},"source":["labels = trash_index.iloc[:,1:].values\n","labels = [list(v).index(1) for v in labels]\n","# s = StratifiedKFold(n_splits=FOLDS, shuffle=True).split(trash_index, labels)\n","s = StratifiedShuffleSplit(n_splits=5, test_size=0.13, random_state=0).split(trash_index, labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJK1JVbzRQq2","colab_type":"code","colab":{}},"source":["train_transform = transforms.Compose([\n","                                transforms.Grayscale(3),\n","                                transforms.Resize(300),\n","                                transforms.RandomResizedCrop(224),\n","                                transforms.RandomVerticalFlip(),\n","                                transforms.RandomHorizontalFlip(),\n","                                transforms.ToTensor(),\n","                                transforms.Normalize([0.485, 0.456, 0.406],\n","                                                     [0.229, 0.224, 0.225])\n","])\n","test_transform = transforms.Compose([\n","                                transforms.Grayscale(3),\n","                                transforms.Resize(300),\n","                                transforms.RandomResizedCrop(224),\n","                                transforms.ToTensor(),\n","                                transforms.Normalize([0.485, 0.456, 0.406],\n","                                                     [0.229, 0.224, 0.225])\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q5fD_WpE0S8N","colab_type":"text"},"source":["### Training and Validation"]},{"cell_type":"code","metadata":{"id":"qp3jvv3l0SHb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1593415106951,"user_tz":-480,"elapsed":1201353,"user":{"displayName":"Alan Sun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAIjD1oE9ht91bAhm8R8PCRYmXLAkyZi1AcXyp=s64","userId":"03211566715491417040"}},"outputId":"1062f9a5-418f-4988-b0cc-3920201dfa8b"},"source":["\n","for fold, (train_idx, test_idx) in enumerate(s):\n","  # Create model and send it to device\n","  model = Net()\n","  model.to(device)\n","\n","  # # Freeze layers that are a part of vgg.\n","  # vgg = next(model.children())\n","  # for param in vgg:\n","  #   if hasattr(param, 'weight') and hasattr(param, 'bias'):\n","  #       param.weight.requires_grad = False\n","  #       param.bias.requires_grad = False\n","  #   param.requires_grad = False\n","\n","  loss = nn.CrossEntropyLoss()\n","  optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n","\n","  # Create TrashData set using newly seperated folds.\n","  train = TrashDataset(trash_index.iloc[train_idx,:], dataset, root, train_transform)\n","  test = TrashDataset(trash_index.iloc[test_idx,:], dataset, root, test_transform)\n","\n","  # Use these fragmented datasets to create dataloaders.\n","  train_loader = torch.utils.data.DataLoader(train, \n","                                             batch_size=BATCH_SIZE,\n","                                             shuffle=True,\n","                                             num_workers=4)\n","  test_loader = torch.utils.data.DataLoader(test, \n","                                             batch_size=BATCH_SIZE,\n","                                             shuffle=True,\n","                                             num_workers=4)\n","\n","  # Wrap dataloaders into a dictionary for ease of access\n","  dataloaders = {'train': train_loader, 'test': test_loader}\n","  best_val = 0.\n","  for epoch in range(EPOCHS):\n","    # Generate Keras-like progress bar\n","    train_steps_per_epoch = len(train) // BATCH_SIZE\n","    test_steps_per_epoch = len(test) // BATCH_SIZE\n","    print(f'Fold: {fold+1} Epochs: {epoch+1}/{EPOCHS} Train for {train_steps_per_epoch} steps, Validate for {test_steps_per_epoch} steps')\n","    kbar = pkbar.Kbar(target=len(train), width=10)\n","\n","    for phase in ['train', 'test']:\n","      if phase == 'train':\n","        model.train()\n","      else:\n","        model.eval()\n","\n","      loss_log = []\n","      f1_log = []\n","      acc_log = [] \n","\n","      for batch_num, inputs in enumerate(dataloaders[phase]):\n","        # Load data onto device: GPU or CPU\n","        images = torch.autograd.Variable(inputs['image'])\n","        labels = torch.autograd.Variable(torch.max(inputs['label'], 1)[1])\n","\n","        images = images.to(device, dtype=torch.float)\n","        labels = labels.to(device, dtype=torch.long)\n","\n","        # Zero the optimizer\n","        optimizer.zero_grad()\n","        \n","        # Forward Feeding\n","        with torch.set_grad_enabled(phase=='train'):\n","          outputs = model(images)\n","          loss_value = loss(outputs, labels)\n","          preds = torch.max(outputs, 1)[1].cpu().detach().numpy()\n","\n","          # Calculating Metrics\n","          acc = accuracy_score(preds, labels.cpu().detach().numpy())\n","          f1 = f1_score(preds, labels.cpu().detach().numpy(), average='micro')\n","\n","          if phase == 'train':\n","            loss_value.backward()\n","            optimizer.step()\n","            kbar.update((batch_num+1) * BATCH_SIZE, values=[('loss', loss_value), \n","                                                            ('f1_score', f1), \n","                                                            ('acc', acc)])\n","          if phase == 'test':\n","            loss_log.append(loss_value)\n","            f1_log.append(f1)\n","            acc_log.append(acc)\n","\n","      if phase == 'test':\n","        kbar.add(1, values=[('val_loss', sum(loss_log)/len(loss_log)), \n","                            ('val_f1_score', sum(f1_log)/len(f1_log)), \n","                            ('val_acc',  sum(acc_log)/len(acc_log))])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fold: 1 Epochs: 1/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 1.3675 - f1_score: 0.5248 - acc: 0.5248\n","2209/2201 [==========] - 23s 10ms/step - loss: 1.3675 - f1_score: 0.5248 - acc: 0.5248 - val_loss: 1.0378 - val_f1_score: 0.6270 - val_acc: 0.6270\n","Fold: 1 Epochs: 2/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 19s 9ms/step - loss: 1.0226 - f1_score: 0.6271 - acc: 0.6271\n","2209/2201 [==========] - 23s 10ms/step - loss: 1.0226 - f1_score: 0.6271 - acc: 0.6271 - val_loss: 0.8116 - val_f1_score: 0.6908 - val_acc: 0.6908\n","Fold: 1 Epochs: 3/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 19s 9ms/step - loss: 0.9113 - f1_score: 0.6725 - acc: 0.6725\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.9113 - f1_score: 0.6725 - acc: 0.6725 - val_loss: 0.8464 - val_f1_score: 0.6858 - val_acc: 0.6858\n","Fold: 1 Epochs: 4/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 19s 9ms/step - loss: 0.8791 - f1_score: 0.6773 - acc: 0.6773\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.8791 - f1_score: 0.6773 - acc: 0.6773 - val_loss: 0.6867 - val_f1_score: 0.7566 - val_acc: 0.7566\n","Fold: 1 Epochs: 5/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.8247 - f1_score: 0.7014 - acc: 0.7014\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.8247 - f1_score: 0.7014 - acc: 0.7014 - val_loss: 0.7298 - val_f1_score: 0.7424 - val_acc: 0.7424\n","Fold: 1 Epochs: 6/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.7557 - f1_score: 0.7236 - acc: 0.7236\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.7557 - f1_score: 0.7236 - acc: 0.7236 - val_loss: 0.6811 - val_f1_score: 0.7381 - val_acc: 0.7381\n","Fold: 1 Epochs: 7/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.7582 - f1_score: 0.7240 - acc: 0.7240\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.7582 - f1_score: 0.7240 - acc: 0.7240 - val_loss: 0.7694 - val_f1_score: 0.7206 - val_acc: 0.7206\n","Fold: 1 Epochs: 8/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 19s 9ms/step - loss: 0.7113 - f1_score: 0.7520 - acc: 0.7520\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.7113 - f1_score: 0.7520 - acc: 0.7520 - val_loss: 0.5667 - val_f1_score: 0.7917 - val_acc: 0.7917\n","Fold: 1 Epochs: 9/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.7185 - f1_score: 0.7442 - acc: 0.7442\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.7185 - f1_score: 0.7442 - acc: 0.7442 - val_loss: 0.6430 - val_f1_score: 0.7335 - val_acc: 0.7335\n","Fold: 1 Epochs: 10/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.6720 - f1_score: 0.7680 - acc: 0.7680\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.6720 - f1_score: 0.7680 - acc: 0.7680 - val_loss: 0.6975 - val_f1_score: 0.7490 - val_acc: 0.7490\n","Fold: 1 Epochs: 11/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 19s 9ms/step - loss: 0.6842 - f1_score: 0.7561 - acc: 0.7561\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.6842 - f1_score: 0.7561 - acc: 0.7561 - val_loss: 0.6663 - val_f1_score: 0.7454 - val_acc: 0.7454\n","Fold: 1 Epochs: 12/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.6471 - f1_score: 0.7634 - acc: 0.7634\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.6471 - f1_score: 0.7634 - acc: 0.7634 - val_loss: 0.6589 - val_f1_score: 0.7526 - val_acc: 0.7526\n","Fold: 1 Epochs: 13/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.6309 - f1_score: 0.7710 - acc: 0.7710\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.6309 - f1_score: 0.7710 - acc: 0.7710 - val_loss: 0.6215 - val_f1_score: 0.7589 - val_acc: 0.7589\n","Fold: 1 Epochs: 14/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.6144 - f1_score: 0.7724 - acc: 0.7724\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.6144 - f1_score: 0.7724 - acc: 0.7724 - val_loss: 0.6668 - val_f1_score: 0.7520 - val_acc: 0.7520\n","Fold: 1 Epochs: 15/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.6088 - f1_score: 0.7790 - acc: 0.7790\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.6088 - f1_score: 0.7790 - acc: 0.7790 - val_loss: 0.6142 - val_f1_score: 0.7877 - val_acc: 0.7877\n","Fold: 1 Epochs: 16/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 19s 9ms/step - loss: 0.5734 - f1_score: 0.8004 - acc: 0.8004\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.5734 - f1_score: 0.8004 - acc: 0.8004 - val_loss: 0.6102 - val_f1_score: 0.7854 - val_acc: 0.7854\n","Fold: 1 Epochs: 17/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 19s 9ms/step - loss: 0.5742 - f1_score: 0.7938 - acc: 0.7938\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.5742 - f1_score: 0.7938 - acc: 0.7938 - val_loss: 0.5330 - val_f1_score: 0.8026 - val_acc: 0.8026\n","Fold: 1 Epochs: 18/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 19s 9ms/step - loss: 0.5595 - f1_score: 0.7978 - acc: 0.7978\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.5595 - f1_score: 0.7978 - acc: 0.7978 - val_loss: 0.6113 - val_f1_score: 0.7923 - val_acc: 0.7923\n","Fold: 1 Epochs: 19/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.5592 - f1_score: 0.8066 - acc: 0.8066\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.5592 - f1_score: 0.8066 - acc: 0.8066 - val_loss: 0.6907 - val_f1_score: 0.7745 - val_acc: 0.7745\n","Fold: 1 Epochs: 20/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4815 - f1_score: 0.8310 - acc: 0.8310\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4815 - f1_score: 0.8310 - acc: 0.8310 - val_loss: 0.5454 - val_f1_score: 0.8155 - val_acc: 0.8155\n","Fold: 1 Epochs: 21/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.5657 - f1_score: 0.8009 - acc: 0.8009\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.5657 - f1_score: 0.8009 - acc: 0.8009 - val_loss: 0.5986 - val_f1_score: 0.8125 - val_acc: 0.8125\n","Fold: 1 Epochs: 22/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.5125 - f1_score: 0.8141 - acc: 0.8141\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.5125 - f1_score: 0.8141 - acc: 0.8141 - val_loss: 0.5765 - val_f1_score: 0.7738 - val_acc: 0.7738\n","Fold: 1 Epochs: 23/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4811 - f1_score: 0.8331 - acc: 0.8331\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4811 - f1_score: 0.8331 - acc: 0.8331 - val_loss: 0.6041 - val_f1_score: 0.7907 - val_acc: 0.7907\n","Fold: 1 Epochs: 24/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4848 - f1_score: 0.8276 - acc: 0.8276\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4848 - f1_score: 0.8276 - acc: 0.8276 - val_loss: 0.5641 - val_f1_score: 0.7864 - val_acc: 0.7864\n","Fold: 1 Epochs: 25/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4808 - f1_score: 0.8222 - acc: 0.8222\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4808 - f1_score: 0.8222 - acc: 0.8222 - val_loss: 0.5555 - val_f1_score: 0.8244 - val_acc: 0.8244\n","Fold: 1 Epochs: 26/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4819 - f1_score: 0.8222 - acc: 0.8222\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4819 - f1_score: 0.8222 - acc: 0.8222 - val_loss: 0.5700 - val_f1_score: 0.7894 - val_acc: 0.7894\n","Fold: 1 Epochs: 27/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4817 - f1_score: 0.8236 - acc: 0.8236\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4817 - f1_score: 0.8236 - acc: 0.8236 - val_loss: 0.6805 - val_f1_score: 0.7841 - val_acc: 0.7841\n","Fold: 1 Epochs: 28/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4794 - f1_score: 0.8323 - acc: 0.8323\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4794 - f1_score: 0.8323 - acc: 0.8323 - val_loss: 0.6741 - val_f1_score: 0.7603 - val_acc: 0.7603\n","Fold: 1 Epochs: 29/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4546 - f1_score: 0.8383 - acc: 0.8383\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4546 - f1_score: 0.8383 - acc: 0.8383 - val_loss: 0.6363 - val_f1_score: 0.7758 - val_acc: 0.7758\n","Fold: 1 Epochs: 30/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4554 - f1_score: 0.8349 - acc: 0.8349\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4554 - f1_score: 0.8349 - acc: 0.8349 - val_loss: 0.6503 - val_f1_score: 0.7847 - val_acc: 0.7847\n","Fold: 1 Epochs: 31/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 19s 9ms/step - loss: 0.4560 - f1_score: 0.8383 - acc: 0.8383\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4560 - f1_score: 0.8383 - acc: 0.8383 - val_loss: 0.5996 - val_f1_score: 0.8125 - val_acc: 0.8125\n","Fold: 1 Epochs: 32/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4298 - f1_score: 0.8452 - acc: 0.8452\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4298 - f1_score: 0.8452 - acc: 0.8452 - val_loss: 0.6626 - val_f1_score: 0.7722 - val_acc: 0.7722\n","Fold: 1 Epochs: 33/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4558 - f1_score: 0.8340 - acc: 0.8340\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4558 - f1_score: 0.8340 - acc: 0.8340 - val_loss: 0.4918 - val_f1_score: 0.8228 - val_acc: 0.8228\n","Fold: 1 Epochs: 34/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4165 - f1_score: 0.8535 - acc: 0.8535\n","2209/2201 [==========] - 23s 11ms/step - loss: 0.4165 - f1_score: 0.8535 - acc: 0.8535 - val_loss: 0.6078 - val_f1_score: 0.7646 - val_acc: 0.7646\n","Fold: 1 Epochs: 35/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4205 - f1_score: 0.8498 - acc: 0.8498\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4205 - f1_score: 0.8498 - acc: 0.8498 - val_loss: 0.5917 - val_f1_score: 0.7669 - val_acc: 0.7669\n","Fold: 1 Epochs: 36/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4185 - f1_score: 0.8530 - acc: 0.8530\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4185 - f1_score: 0.8530 - acc: 0.8530 - val_loss: 0.6019 - val_f1_score: 0.7662 - val_acc: 0.7662\n","Fold: 1 Epochs: 37/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4419 - f1_score: 0.8508 - acc: 0.8508\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4419 - f1_score: 0.8508 - acc: 0.8508 - val_loss: 0.6230 - val_f1_score: 0.7989 - val_acc: 0.7989\n","Fold: 1 Epochs: 38/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4291 - f1_score: 0.8476 - acc: 0.8476\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4291 - f1_score: 0.8476 - acc: 0.8476 - val_loss: 0.7019 - val_f1_score: 0.7698 - val_acc: 0.7698\n","Fold: 1 Epochs: 39/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 19s 9ms/step - loss: 0.4136 - f1_score: 0.8535 - acc: 0.8535\n","2209/2201 [==========] - 22s 10ms/step - loss: 0.4136 - f1_score: 0.8535 - acc: 0.8535 - val_loss: 0.6017 - val_f1_score: 0.7870 - val_acc: 0.7870\n","Fold: 1 Epochs: 40/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 19s 9ms/step - loss: 0.3691 - f1_score: 0.8715 - acc: 0.8715\n","2209/2201 [==========] - 22s 10ms/step - loss: 0.3691 - f1_score: 0.8715 - acc: 0.8715 - val_loss: 0.5131 - val_f1_score: 0.8280 - val_acc: 0.8280\n","Fold: 1 Epochs: 41/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4247 - f1_score: 0.8470 - acc: 0.8470\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4247 - f1_score: 0.8470 - acc: 0.8470 - val_loss: 0.5442 - val_f1_score: 0.8185 - val_acc: 0.8185\n","Fold: 1 Epochs: 42/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.4132 - f1_score: 0.8590 - acc: 0.8590\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.4132 - f1_score: 0.8590 - acc: 0.8590 - val_loss: 0.5009 - val_f1_score: 0.8251 - val_acc: 0.8251\n","Fold: 1 Epochs: 43/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 19s 9ms/step - loss: 0.3783 - f1_score: 0.8638 - acc: 0.8638\n","2209/2201 [==========] - 22s 10ms/step - loss: 0.3783 - f1_score: 0.8638 - acc: 0.8638 - val_loss: 0.5737 - val_f1_score: 0.7989 - val_acc: 0.7989\n","Fold: 1 Epochs: 44/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 19s 9ms/step - loss: 0.3819 - f1_score: 0.8598 - acc: 0.8598\n","2209/2201 [==========] - 22s 10ms/step - loss: 0.3819 - f1_score: 0.8598 - acc: 0.8598 - val_loss: 0.6039 - val_f1_score: 0.8079 - val_acc: 0.8079\n","Fold: 1 Epochs: 45/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 19s 8ms/step - loss: 0.3950 - f1_score: 0.8649 - acc: 0.8649\n","2209/2201 [==========] - 22s 10ms/step - loss: 0.3950 - f1_score: 0.8649 - acc: 0.8649 - val_loss: 0.7731 - val_f1_score: 0.7252 - val_acc: 0.7252\n","Fold: 1 Epochs: 46/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 19s 9ms/step - loss: 0.3555 - f1_score: 0.8778 - acc: 0.8778\n","2209/2201 [==========] - 22s 10ms/step - loss: 0.3555 - f1_score: 0.8778 - acc: 0.8778 - val_loss: 0.5610 - val_f1_score: 0.7973 - val_acc: 0.7973\n","Fold: 1 Epochs: 47/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 19s 9ms/step - loss: 0.3620 - f1_score: 0.8725 - acc: 0.8725\n","2209/2201 [==========] - 22s 10ms/step - loss: 0.3620 - f1_score: 0.8725 - acc: 0.8725 - val_loss: 0.4900 - val_f1_score: 0.8340 - val_acc: 0.8340\n","Fold: 1 Epochs: 48/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.3530 - f1_score: 0.8783 - acc: 0.8783\n","2209/2201 [==========] - 23s 10ms/step - loss: 0.3530 - f1_score: 0.8783 - acc: 0.8783 - val_loss: 0.5729 - val_f1_score: 0.8310 - val_acc: 0.8310\n","Fold: 1 Epochs: 49/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.3756 - f1_score: 0.8700 - acc: 0.8700\n","2209/2201 [==========] - 24s 11ms/step - loss: 0.3756 - f1_score: 0.8700 - acc: 0.8700 - val_loss: 0.6398 - val_f1_score: 0.7847 - val_acc: 0.7847\n","Fold: 1 Epochs: 50/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.3269 - f1_score: 0.8801 - acc: 0.8801\n","2209/2201 [==========] - 24s 11ms/step - loss: 0.3269 - f1_score: 0.8801 - acc: 0.8801 - val_loss: 0.6025 - val_f1_score: 0.8108 - val_acc: 0.8108\n","Fold: 1 Epochs: 51/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.3953 - f1_score: 0.8517 - acc: 0.8517\n","2209/2201 [==========] - 24s 11ms/step - loss: 0.3953 - f1_score: 0.8517 - acc: 0.8517 - val_loss: 0.6333 - val_f1_score: 0.7735 - val_acc: 0.7735\n","Fold: 1 Epochs: 52/150 Train for 137 steps, Validate for 20 steps\n","2208/2201 [==========] - 20s 9ms/step - loss: 0.3660 - f1_score: 0.8693 - acc: 0.8693\n","2209/2201 [==========] - 24s 11ms/step - loss: 0.3660 - f1_score: 0.8693 - acc: 0.8693 - val_loss: 0.6853 - val_f1_score: 0.7946 - val_acc: 0.7946\n","Fold: 1 Epochs: 53/150 Train for 137 steps, Validate for 20 steps\n"," 928/2201 [===>......] - ETA: 12s - loss: 0.3685 - f1_score: 0.8804 - acc: 0.8804"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-2231261ed903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             kbar.update((batch_num+1) * BATCH_SIZE, values=[('loss', loss_value), \n\u001b[1;32m     77\u001b[0m                                                             \u001b[0;34m(\u001b[0m\u001b[0;34m'f1_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}