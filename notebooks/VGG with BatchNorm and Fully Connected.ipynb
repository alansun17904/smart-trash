{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvOLHpULfCkx"
   },
   "source": [
    "# Baseline Transfer Learning Model for TrashNet Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p1YGdWgaxh0V"
   },
   "source": [
    "Our baseline model will include a pretrained DenseNet feature extractor with a shallow and wide CNN head. This model will have a homogenous learning rate. We are going to use K-Fold CV as well as F1 score and multi-class AUC to validate our model.\n",
    "\n",
    "This model acts as a stepping stone / template for future experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4889,
     "status": "ok",
     "timestamp": 1593251499951,
     "user": {
      "displayName": "Alan Sun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiAIjD1oE9ht91bAhm8R8PCRYmXLAkyZi1AcXyp=s64",
      "userId": "03211566715491417040"
     },
     "user_tz": -480
    },
    "id": "a3yToMaN05im",
    "outputId": "5ff92424-2bcb-468e-d635-cf5b9a843b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pkbar in /usr/local/lib/python3.6/dist-packages (0.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pkbar) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pkbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6189,
     "status": "ok",
     "timestamp": 1593251501263,
     "user": {
      "displayName": "Alan Sun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiAIjD1oE9ht91bAhm8R8PCRYmXLAkyZi1AcXyp=s64",
      "userId": "03211566715491417040"
     },
     "user_tz": -480
    },
    "id": "8RsfLTKGf7mD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pkbar\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9_bhYNXDb_KV"
   },
   "source": [
    "## Data Pre-processing\n",
    "For the baseline model, we will not be applying any data augmentation or color manipulation.\n",
    "- Get the index CSV file that includes all files their respective directory and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6161,
     "status": "ok",
     "timestamp": 1593251501265,
     "user": {
      "displayName": "Alan Sun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiAIjD1oE9ht91bAhm8R8PCRYmXLAkyZi1AcXyp=s64",
      "userId": "03211566715491417040"
     },
     "user_tz": -480
    },
    "id": "GoEjfYONFGIz"
   },
   "outputs": [],
   "source": [
    "dataset = 'trashnet'\n",
    "csv_path = os.path.join(os.path.join(root, dataset), f'{dataset}_index.csv')\n",
    "trash_index = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6152,
     "status": "ok",
     "timestamp": 1593251501265,
     "user": {
      "displayName": "Alan Sun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiAIjD1oE9ht91bAhm8R8PCRYmXLAkyZi1AcXyp=s64",
      "userId": "03211566715491417040"
     },
     "user_tz": -480
    },
    "id": "AK2sRJtkh5Nn",
    "outputId": "e1e9bf19-5cd2-42ce-a515-af85318ec398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Filename  metal  cardboard  paper  trash  glass  plastic\n",
      "0         metal/metal282.jpg      1          0      0      0      0        0\n",
      "1         metal/metal296.jpg      1          0      0      0      0        0\n",
      "2           metal/metal2.jpg      1          0      0      0      0        0\n",
      "3         metal/metal255.jpg      1          0      0      0      0        0\n",
      "4         metal/metal241.jpg      1          0      0      0      0        0\n",
      "...                      ...    ...        ...    ...    ...    ...      ...\n",
      "2525  plastic/plastic441.jpg      0          0      0      0      0        1\n",
      "2526  plastic/plastic482.jpg      0          0      0      0      0        1\n",
      "2527  plastic/plastic327.jpg      0          0      0      0      0        1\n",
      "2528  plastic/plastic323.jpg      0          0      0      0      0        1\n",
      "2529  plastic/plastic109.jpg      0          0      0      0      0        1\n",
      "\n",
      "[2530 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(trash_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aPhbaYIAqQDq"
   },
   "source": [
    "### Trash Dataset\n",
    "Dataset object to handle various sets of data that we will be dealing with including: TrashNet, ISBNet, and ISBNet extended.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6141,
     "status": "ok",
     "timestamp": 1593251501266,
     "user": {
      "displayName": "Alan Sun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiAIjD1oE9ht91bAhm8R8PCRYmXLAkyZi1AcXyp=s64",
      "userId": "03211566715491417040"
     },
     "user_tz": -480
    },
    "id": "hY5KgUVwxXFz"
   },
   "outputs": [],
   "source": [
    "class TrashDataset(Dataset):\n",
    "  def __init__(self, csv_file, directory, root_dir, transform=None):\n",
    "    \"\"\"\n",
    "    csv_file: CSV file that contains information about each image and their labels.\n",
    "    directory: the directory where the trash data is kept\n",
    "    root_dir: path to the `directory`\n",
    "    transform: optional augmentations that are to be applied onto the images\n",
    "    \"\"\"\n",
    "    self.images = os.path.join(root_dir, directory)\n",
    "    self.csv = csv_file\n",
    "    self.transform = transform\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.csv)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    if torch.is_tensor(idx):\n",
    "      idx = idx.tolist()\n",
    "    \n",
    "    img_name = os.path.join(self.images, self.csv.iloc[idx, 0])\n",
    "    image = Image.open(img_name)\n",
    "    labels = self.csv.iloc[idx, 1:]\n",
    "    sample = {'image': image,\n",
    "              'label': torch.tensor(labels.tolist(), dtype=torch.float)}\n",
    "\n",
    "    if self.transform:\n",
    "      sample['image'] = self.transform(sample['image'])\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dr8dFmpmteKB"
   },
   "source": [
    "## Model and Training Setup\n",
    "- VGG16 pretrained with ImageNet\n",
    "- Wide and shallow CNN with fully connected and log-softmax activation\n",
    "- CrossEntropy loss and Adam optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2sR1CiTexs0z"
   },
   "source": [
    "### Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6129,
     "status": "ok",
     "timestamp": 1593251501266,
     "user": {
      "displayName": "Alan Sun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiAIjD1oE9ht91bAhm8R8PCRYmXLAkyZi1AcXyp=s64",
      "userId": "03211566715491417040"
     },
     "user_tz": -480
    },
    "id": "eSjjNBUlxxiv"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aVySPVh1uVy9"
   },
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6120,
     "status": "ok",
     "timestamp": 1593251501267,
     "user": {
      "displayName": "Alan Sun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiAIjD1oE9ht91bAhm8R8PCRYmXLAkyZi1AcXyp=s64",
      "userId": "03211566715491417040"
     },
     "user_tz": -480
    },
    "id": "t5ovoB5fuaox"
   },
   "outputs": [],
   "source": [
    "FOLDS = 5\n",
    "EPOCHS = 150\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FqhMCfX0s5wr"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6108,
     "status": "ok",
     "timestamp": 1593251501267,
     "user": {
      "displayName": "Alan Sun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiAIjD1oE9ht91bAhm8R8PCRYmXLAkyZi1AcXyp=s64",
      "userId": "03211566715491417040"
     },
     "user_tz": -480
    },
    "id": "1IHUz16JsA2i"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.model = models.vgg16_bn(pretrained=True)\n",
    "    # Remove classification layers so that we are able to add our own CNN layers\n",
    "    self.model.classifier[6] = nn.Sequential(\n",
    "                                nn.Linear(4096, 1024, bias=True),\n",
    "                                nn.BatchNorm1d(1024),\n",
    "                                nn.Dropout(.25),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(1024, 512, bias=True),\n",
    "                                nn.BatchNorm1d(512),\n",
    "                                nn.Dropout(.5),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(512, 6, bias=True),\n",
    "                                nn.LogSoftmax(dim=0))\n",
    "  def forward(self, x):\n",
    "    return self.model(x)\n",
    "  \n",
    "  def num_flat_features(self, x):\n",
    "    \"\"\"\n",
    "    https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py\n",
    "    \"\"\"\n",
    "    size = x.size()[1:]  # get all dimensions except for batch size\n",
    "    features = 1\n",
    "    for s in size:\n",
    "      features *= s\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FRRDY5q7uzRy"
   },
   "source": [
    "### KFold Training and CV\n",
    "* KFold setup with `StratifiedKFold`\n",
    "* Creating Dataloaders in training loop.\n",
    "* Using Adam and CrossEntropy Loss\n",
    "* Center crop on images to make them 224x224 so VGG will be able to take them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6098,
     "status": "ok",
     "timestamp": 1593251501268,
     "user": {
      "displayName": "Alan Sun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiAIjD1oE9ht91bAhm8R8PCRYmXLAkyZi1AcXyp=s64",
      "userId": "03211566715491417040"
     },
     "user_tz": -480
    },
    "id": "BM_t7ZnBuUaK"
   },
   "outputs": [],
   "source": [
    "labels = trash_index.iloc[:,1:].values\n",
    "labels = [list(v).index(1) for v in labels]\n",
    "# s = StratifiedKFold(n_splits=FOLDS, shuffle=True).split(trash_index, labels)\n",
    "s = StratifiedShuffleSplit(n_splits=5, test_size=0.17, random_state=0).split(trash_index, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6089,
     "status": "ok",
     "timestamp": 1593251501269,
     "user": {
      "displayName": "Alan Sun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiAIjD1oE9ht91bAhm8R8PCRYmXLAkyZi1AcXyp=s64",
      "userId": "03211566715491417040"
     },
     "user_tz": -480
    },
    "id": "CJK1JVbzRQq2"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                                transforms.Resize(300),\n",
    "                                transforms.RandomResizedCrop(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                     [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q5fD_WpE0S8N"
   },
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 781664,
     "status": "error",
     "timestamp": 1593252276863,
     "user": {
      "displayName": "Alan Sun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiAIjD1oE9ht91bAhm8R8PCRYmXLAkyZi1AcXyp=s64",
      "userId": "03211566715491417040"
     },
     "user_tz": -480
    },
    "id": "qp3jvv3l0SHb",
    "outputId": "d519be2c-3b35-4d3b-b886-aa3177e2c94a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1 Epochs: 1/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 227s 108ms/step - loss: 1.4970 - f1_score: 0.4327 - acc: 0.4327\n",
      "2113/2099 [==========] - 279s 132ms/step - loss: 1.4970 - f1_score: 0.4327 - acc: 0.4327 - val_loss: 2.3929 - val_f1_score: 0.3943 - val_acc: 0.3943\n",
      "Fold: 1 Epochs: 2/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 22s 11ms/step - loss: 1.3923 - f1_score: 0.4743 - acc: 0.4743\n",
      "2113/2099 [==========] - 26s 12ms/step - loss: 1.3923 - f1_score: 0.4743 - acc: 0.4743 - val_loss: 1.8898 - val_f1_score: 0.4220 - val_acc: 0.4220\n",
      "Fold: 1 Epochs: 3/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 23s 11ms/step - loss: 1.2932 - f1_score: 0.5099 - acc: 0.5099\n",
      "2113/2099 [==========] - 27s 13ms/step - loss: 1.2932 - f1_score: 0.5099 - acc: 0.5099 - val_loss: 1.3149 - val_f1_score: 0.4842 - val_acc: 0.4842\n",
      "Fold: 1 Epochs: 4/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 23s 11ms/step - loss: 1.2219 - f1_score: 0.5348 - acc: 0.5348\n",
      "2113/2099 [==========] - 27s 13ms/step - loss: 1.2219 - f1_score: 0.5348 - acc: 0.5348 - val_loss: 1.2495 - val_f1_score: 0.5473 - val_acc: 0.5473\n",
      "Fold: 1 Epochs: 5/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 22s 11ms/step - loss: 1.0910 - f1_score: 0.6036 - acc: 0.6036\n",
      "2113/2099 [==========] - 26s 13ms/step - loss: 1.0910 - f1_score: 0.6036 - acc: 0.6036 - val_loss: 1.0838 - val_f1_score: 0.6372 - val_acc: 0.6372\n",
      "Fold: 1 Epochs: 6/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 22s 11ms/step - loss: 1.0694 - f1_score: 0.6131 - acc: 0.6131\n",
      "2113/2099 [==========] - 26s 12ms/step - loss: 1.0694 - f1_score: 0.6131 - acc: 0.6131 - val_loss: 1.1563 - val_f1_score: 0.5760 - val_acc: 0.5760\n",
      "Fold: 1 Epochs: 7/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 22s 11ms/step - loss: 1.0297 - f1_score: 0.6173 - acc: 0.6173\n",
      "2113/2099 [==========] - 27s 13ms/step - loss: 1.0297 - f1_score: 0.6173 - acc: 0.6173 - val_loss: 0.9895 - val_f1_score: 0.6372 - val_acc: 0.6372\n",
      "Fold: 1 Epochs: 8/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 22s 11ms/step - loss: 0.9842 - f1_score: 0.6324 - acc: 0.6324\n",
      "2113/2099 [==========] - 27s 13ms/step - loss: 0.9842 - f1_score: 0.6324 - acc: 0.6324 - val_loss: 1.0292 - val_f1_score: 0.6263 - val_acc: 0.6263\n",
      "Fold: 1 Epochs: 9/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 23s 11ms/step - loss: 0.9996 - f1_score: 0.6291 - acc: 0.6291\n",
      "2113/2099 [==========] - 27s 13ms/step - loss: 0.9996 - f1_score: 0.6291 - acc: 0.6291 - val_loss: 1.0245 - val_f1_score: 0.6095 - val_acc: 0.6095\n",
      "Fold: 1 Epochs: 10/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 23s 11ms/step - loss: 0.9877 - f1_score: 0.6470 - acc: 0.6470\n",
      "2113/2099 [==========] - 27s 13ms/step - loss: 0.9877 - f1_score: 0.6470 - acc: 0.6470 - val_loss: 0.8446 - val_f1_score: 0.6821 - val_acc: 0.6821\n",
      "Fold: 1 Epochs: 11/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 22s 11ms/step - loss: 0.9212 - f1_score: 0.6625 - acc: 0.6625\n",
      "2113/2099 [==========] - 26s 13ms/step - loss: 0.9212 - f1_score: 0.6625 - acc: 0.6625 - val_loss: 1.1684 - val_f1_score: 0.6115 - val_acc: 0.6115\n",
      "Fold: 1 Epochs: 12/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 23s 11ms/step - loss: 0.8966 - f1_score: 0.6709 - acc: 0.6709\n",
      "2113/2099 [==========] - 27s 13ms/step - loss: 0.8966 - f1_score: 0.6709 - acc: 0.6709 - val_loss: 0.9926 - val_f1_score: 0.6592 - val_acc: 0.6592\n",
      "Fold: 1 Epochs: 13/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 22s 11ms/step - loss: 0.9205 - f1_score: 0.6602 - acc: 0.6602\n",
      "2113/2099 [==========] - 27s 13ms/step - loss: 0.9205 - f1_score: 0.6602 - acc: 0.6602 - val_loss: 1.0955 - val_f1_score: 0.6193 - val_acc: 0.6193\n",
      "Fold: 1 Epochs: 14/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 23s 11ms/step - loss: 0.8564 - f1_score: 0.6849 - acc: 0.6849\n",
      "2113/2099 [==========] - 27s 13ms/step - loss: 0.8564 - f1_score: 0.6849 - acc: 0.6849 - val_loss: 0.8652 - val_f1_score: 0.6815 - val_acc: 0.6815\n",
      "Fold: 1 Epochs: 15/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 23s 11ms/step - loss: 0.8636 - f1_score: 0.6898 - acc: 0.6898\n",
      "2113/2099 [==========] - 27s 13ms/step - loss: 0.8636 - f1_score: 0.6898 - acc: 0.6898 - val_loss: 0.9788 - val_f1_score: 0.6558 - val_acc: 0.6558\n",
      "Fold: 1 Epochs: 16/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 23s 11ms/step - loss: 0.8610 - f1_score: 0.6892 - acc: 0.6892\n",
      "2113/2099 [==========] - 27s 13ms/step - loss: 0.8610 - f1_score: 0.6892 - acc: 0.6892 - val_loss: 0.8186 - val_f1_score: 0.7201 - val_acc: 0.7201\n",
      "Fold: 1 Epochs: 17/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 23s 11ms/step - loss: 0.8226 - f1_score: 0.7049 - acc: 0.7049\n",
      "2113/2099 [==========] - 27s 13ms/step - loss: 0.8226 - f1_score: 0.7049 - acc: 0.7049 - val_loss: 0.9620 - val_f1_score: 0.6701 - val_acc: 0.6701\n",
      "Fold: 1 Epochs: 18/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 23s 11ms/step - loss: 0.8492 - f1_score: 0.6969 - acc: 0.6969\n",
      "2113/2099 [==========] - 27s 13ms/step - loss: 0.8492 - f1_score: 0.6969 - acc: 0.6969 - val_loss: 0.7997 - val_f1_score: 0.7249 - val_acc: 0.7249\n",
      "Fold: 1 Epochs: 19/150 Train for 65 steps, Validate for 13 steps\n",
      "2112/2099 [==========] - 22s 11ms/step - loss: 0.7697 - f1_score: 0.7296 - acc: 0.7296\n",
      "2113/2099 [==========] - 26s 13ms/step - loss: 0.7697 - f1_score: 0.7296 - acc: 0.7296 - val_loss: 0.8677 - val_f1_score: 0.6746 - val_acc: 0.6746\n",
      "Fold: 1 Epochs: 20/150 Train for 65 steps, Validate for 13 steps\n",
      "1152/2099 [====>.....] - ETA: 10s - loss: 0.7889 - f1_score: 0.7144 - acc: 0.7144"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-49c4a7cdbdd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(s):\n",
    "  # Create model and send it to device\n",
    "  model = Net()\n",
    "  model.to(device)\n",
    "\n",
    "  # Freeze layers that are a part of vgg.\n",
    "  # c = 0\n",
    "  # vgg = next(model.children())\n",
    "  # for param in vgg:\n",
    "  #     if c <= 39:\n",
    "  #         if hasattr(param, 'weight') and hasattr(param, 'bias'):\n",
    "  #             param.weight.requires_grad = False\n",
    "  #             param.bias.requires_grad = False\n",
    "  #         param.requires_grad = False\n",
    "\n",
    "  #     c += 1\n",
    "\n",
    "  loss = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "\n",
    "  # Create TrashData set using newly seperated folds.\n",
    "  train = TrashDataset(trash_index.iloc[train_idx,:], dataset, root, transform)\n",
    "  test = TrashDataset(trash_index.iloc[test_idx,:], dataset, root, transform)\n",
    "\n",
    "  # Use these fragmented datasets to create dataloaders.\n",
    "  train_loader = torch.utils.data.DataLoader(train, \n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=4)\n",
    "  test_loader = torch.utils.data.DataLoader(test, \n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=4)\n",
    "\n",
    "  # Wrap dataloaders into a dictionary for ease of access\n",
    "  dataloaders = {'train': train_loader, 'test': test_loader}\n",
    "  best_val = 0.\n",
    "  for epoch in range(EPOCHS):\n",
    "    # Generate Keras-like progress bar\n",
    "    train_steps_per_epoch = len(train) // BATCH_SIZE\n",
    "    test_steps_per_epoch = len(test) // BATCH_SIZE\n",
    "    print(f'Fold: {fold+1} Epochs: {epoch+1}/{EPOCHS} Train for {train_steps_per_epoch} steps, Validate for {test_steps_per_epoch} steps')\n",
    "    kbar = pkbar.Kbar(target=len(train), width=10)\n",
    "\n",
    "    for phase in ['train', 'test']:\n",
    "      if phase == 'train':\n",
    "        model.train()\n",
    "      else:\n",
    "        model.eval()\n",
    "\n",
    "      loss_log = []\n",
    "      f1_log = []\n",
    "      acc_log = [] \n",
    "\n",
    "      for batch_num, inputs in enumerate(dataloaders[phase]):\n",
    "        # Load data onto device: GPU or CPU\n",
    "        images = torch.autograd.Variable(inputs['image'])\n",
    "        labels = torch.autograd.Variable(torch.max(inputs['label'], 1)[1])\n",
    "\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "        # Zero the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward Feeding\n",
    "        with torch.set_grad_enabled(phase=='train'):\n",
    "          outputs = model(images)\n",
    "          loss_value = loss(outputs, labels)\n",
    "          preds = torch.max(outputs, 1)[1].cpu().detach().numpy()\n",
    "\n",
    "          # Calculating Metrics\n",
    "          acc = accuracy_score(preds, labels.cpu().detach().numpy())\n",
    "          f1 = f1_score(preds, labels.cpu().detach().numpy(), average='micro')\n",
    "\n",
    "          if phase == 'train':\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            kbar.update((batch_num+1) * BATCH_SIZE, values=[('loss', loss_value), \n",
    "                                                            ('f1_score', f1), \n",
    "                                                            ('acc', acc)])\n",
    "          if phase == 'test':\n",
    "            loss_log.append(loss_value)\n",
    "            f1_log.append(f1)\n",
    "            acc_log.append(acc)\n",
    "\n",
    "      if phase == 'test':\n",
    "        kbar.add(1, values=[('val_loss', sum(loss_log)/len(loss_log)), \n",
    "                            ('val_f1_score', sum(f1_log)/len(f1_log)), \n",
    "                            ('val_acc',  sum(acc_log)/len(acc_log))])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VGG with BatchNorm and Fully Connected.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "name": "python_universal"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
